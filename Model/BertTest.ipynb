{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19325,"status":"ok","timestamp":1681379539908,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"tLHxnOuHfMxv","outputId":"8eb92071-da23-47e7-d7af-5ba48368b588"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["# To mount google drive onto google colab\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3979,"status":"ok","timestamp":1681379543876,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"9QtY9GATf56r"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2036,"status":"ok","timestamp":1681379545903,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"NwmNfdDwfb8c"},"outputs":[],"source":["# Load the dataset\n","df = pd.read_csv('FYPDATASET/balanced.csv')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1681379545904,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"88CQ3kyKf9fJ","outputId":"fea27de0-7690-4324-bb79-51131df20868"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>best candy corn on the planet ill keep this sh...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cat food my cats eat it that is all i can say ...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>onions overwhelm otherwise lowkey flavor the o...</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yummy tasted good spicy those that dont like s...</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>good flavor the product is the same as what we...</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Review Sentiment\n","0  best candy corn on the planet ill keep this sh...  Positive\n","1  cat food my cats eat it that is all i can say ...  Positive\n","2  onions overwhelm otherwise lowkey flavor the o...  Negative\n","3  yummy tasted good spicy those that dont like s...  Positive\n","4  good flavor the product is the same as what we...  Positive"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Dataset is already preprocessed\n","df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1681379546361,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"WJIvb7r2f-oq","outputId":"5f26703a-5b2b-4603-e829-d9ef3e139249"},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive    82037\n","Negative    82037\n","Name: Sentiment, dtype: int64\n"]}],"source":["value_counts = df['Sentiment'].value_counts()\n","\n","print(value_counts)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1681379546362,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"JaTq8w9khyUt"},"outputs":[],"source":["df['Value'] = df['Sentiment'].apply(lambda x: 1 if 'Positive' in x else 0)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681379546362,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"STMNucSQh53T"},"outputs":[],"source":["df = df[['Review', 'Value']]"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1681379546363,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"pane10KoN_n4"},"outputs":[],"source":["df = df.head(10000)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1681354869289,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"7KDTyKEiiNXo","outputId":"12eb522d-3c15-4c7c-8586-72a8c1937182"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>best candy corn on the planet ill keep this sh...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cat food my cats eat it that is all i can say ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>onions overwhelm otherwise lowkey flavor the o...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yummy tasted good spicy those that dont like s...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>good flavor the product is the same as what we...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Review  Value\n","0  best candy corn on the planet ill keep this sh...      1\n","1  cat food my cats eat it that is all i can say ...      1\n","2  onions overwhelm otherwise lowkey flavor the o...      0\n","3  yummy tasted good spicy those that dont like s...      1\n","4  good flavor the product is the same as what we...      1"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df.head()\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["2c1b080a3a0643f2abb5dd92d17c829f","98bf441dffef40e79f60edd5ed092cf4","4d801d28d0074b3da3a00add13c87dcb","ba3ea9f9af844077bc283027afffe0b4","8937f14c0ca4400092fbf1d58112d5ce","4bf63e5a7fdf42ed82a0f0b358d98d1a","c43db8ce97c44b87a615ea96dec50cab","2baa9fb8bb564c11b8f8f5e873bba6df","d779c69f8f7747338a053a5436704e1e","b666eb5581e94905970d60d12c2745ca","828de62350c741a880823c0ee0c5a151","8ae9c45ab3144f508c23140c17a92e80","d8251598d5de4a14a3e2891fd1591a49","94808fcd55094fceb980d0cb2b9af30e","380e65e0017948c09b25239ad9067d24","af94071ef9c44c8490be16481298c1a0","20bdc3bd3354413ab254e9a9200241b3","7b1743dab6fd4ae49a3e23c7110051ed","627b2ca479474d6a9a867145944b8b65","b54a35fd75284d0e8f1fded5ec0f53ed","a363bb993ca346629f8c3e47e251df8a","234beff55041477a9a2046c89f113b11","d18abdd653bb4aa1be0b4db3310c4255","4749f2be937840d1b13cd6c9a43b71d7","9f25d6361e3345f99a3ad013ca484288","76a0cbb389744428b579a5f3a2232759","d8fb5d72c4bb4fb68e6793cc6c83e9ae","88ce237423c94595b19b68c34106fa52","60df1875f5c34aa89ae74abb93b1f9a4","75f89bc8cb6940cc949c97db52449e26","00163ee06c46415fb0e827656d3ccb94","62d450eb94a847d4b6b85844f608f122","0beaf9115c684616aa1e1480fd999ce1"]},"executionInfo":{"elapsed":1923,"status":"ok","timestamp":1681379628379,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"9I1f8FX-iVqY","outputId":"c9807322-23cc-43ff-c7a8-d2847bd98f6e"},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1681379628380,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"AGdrN8wgvep5","outputId":"6d13f04c-5e42-4a4a-af1a-9f8c67bbfe52"},"outputs":[{"name":"stdout","output_type":"stream","text":["int64\n"]}],"source":["score_dtype = df['Value'].dtype\n","\n","print(score_dtype) "]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1681379628380,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"rGlIojaKir6H"},"outputs":[],"source":["# Get the lists of sentences and their labels.\n","sentences = df[\"Review\"]\n","labels = df[\"Value\"]"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1681379628380,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"x_2irTAti876","outputId":"ea01dd04-0420-40e4-9d5a-b89a28c1c2f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["10000\n","10000\n"]}],"source":["print(len(sentences))\n","print(len(labels))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36632,"status":"ok","timestamp":1681379665006,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"XFLxANlGjJh6","outputId":"c623ce11-c6a7-4465-ed39-210a98398a05"},"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n"]},{"name":"stdout","output_type":"stream","text":["Max sentence length:  1905\n"]}],"source":["max_len = 0\n","\n","for sent in sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max length: ', max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n"," \n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":5301,"status":"ok","timestamp":1681379670283,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"2TKlkcOnsTIa"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22955,"status":"ok","timestamp":1681379693221,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"357eKVJkqTsc","outputId":"16410095-189d-4edb-f2bf-e237ffdf11b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original:  best candy corn on the planet ill keep this sho and sweet  i have a sweet tooth and i love candy corn  i also love caramels  this candy corn brings a whole new light on the candy corn industry and if you havent tried them yet pick up a bagbest candy ever\n","Token IDs: tensor([  101,  2190,  9485,  9781,  2006,  1996,  4774,  5665,  2562,  2023,\n","        26822,  1998,  4086,  1045,  2031,  1037,  4086, 11868,  1998,  1045,\n","         2293,  9485,  9781,  1045,  2036,  2293, 14418, 10199,  2015,  2023,\n","         9485,  9781,  7545,  1037,  2878,  2047,  2422,  2006,  1996,  9485,\n","         9781,  3068,  1998,  2065,  2017,  4033,  2102,  2699,  2068,  2664,\n","         4060,  2039,  1037,  4524, 12681,  2102,  9485,  2412,   102,     0,\n","            0,     0,     0,     0])\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\USER\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]}],"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in sentences:\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,      \n","                        truncation=True,               \n","                        add_special_tokens = True, \n","                        max_length = 64,           \n","                        pad_to_max_length = True,\n","                        return_attention_mask = True, \n","                        return_tensors = 'pt',   \n","                   )\n","    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1681379693222,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"LNrvENAHtrBA","outputId":"48407470-657b-47ca-dd87-78dd2d87daec"},"outputs":[{"name":"stdout","output_type":"stream","text":["training samples\n","9000\n","validation samples\n","1000\n"]}],"source":["from torch.utils.data import TensorDataset, random_split\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('training samples')\n","print(train_size)\n","print('validation samples')\n","print(val_size)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1681379693223,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"tREYUvS4tvNC"},"outputs":[],"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","\n","batch_size = 32\n","\n","train_dataloader = DataLoader(\n","            train_dataset, \n","            sampler = RandomSampler(train_dataset), \n","            batch_size = batch_size \n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset,\n","            sampler = SequentialSampler(val_dataset),\n","            batch_size = batch_size \n","        )"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159,"referenced_widgets":["b658939b3a164fa38186f05449166510","f04d400437a4404bb8d6e078d7a72915","547bf843181c485f956553bf6d49d3db","58cb8602816f448592eb31e323c088b8","af027a9213124ca2bdc15a8571243424","d25f1c4a70d74e29a1f4936c454a2601","d751f34b3bc34064af9b2b8fc533e6c8","eb6350825aa14b3bb2ae3eed42175de4","745baf921e454c569a8a686ba414c664","6347aab46197450cba320a4ad86a91a2","fc945f6679304803b67a8ddbd21a2b65"]},"executionInfo":{"elapsed":4009,"status":"ok","timestamp":1681379697211,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"z81knfAJtyYb","outputId":"0bdc3a50-bffa-4ac0-fe2b-a2a2a68e88cc"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForSequenceClassification, AdamW\n","\n","\n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", \n","    num_labels = 2,       \n","    output_attentions = False, \n","    output_hidden_states = False,\n",")\n","\n"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1681355005156,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"sMxfJfYCt-VY","outputId":"92793d30-2a6c-49fe-d450-8d1916915fc6"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, \n","                  eps = 1e-8\n","                )\n"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1681355005157,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"YGedR8ByuCHd"},"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# The BERT authors recommend between 2 and 4. \n","epochs = 2\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1681355005157,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"H3IBHtJeuEgg"},"outputs":[],"source":["import numpy as np\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1681355005158,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"G_tPyJtXu9U0","outputId":"b027fc1c-3754-4839-f1e1-a559dc178536"},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU available, using the CPU instead.\n"]}],"source":["import torch\n","\n","# GPU setup\n","if torch.cuda.is_available():    \n","\n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9803427,"status":"ok","timestamp":1681367018229,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"HcLwQ1kguKAf","outputId":"d5207e1c-12ce-4414-bb6a-95f05fd800cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-46-c58d238a41c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import random\n","import numpy as np\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","\n","training_stats = []\n","\n","# Measure the total training time\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            \n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","\n","        # outputs prior to activation.\n","        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        loss = output.loss\n","        logits = output.logits\n","\n","  \n","        total_train_loss += loss.item()\n","\n","        loss.backward()\n","\n","       \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","   \n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n"," \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","\n","        with torch.no_grad():        \n","\n","            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","            loss = output.loss\n","            logits = output.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","     \n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60205,"status":"ok","timestamp":1681368525727,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"9rcV8jHXXrU6","outputId":"c9980a2d-2c6d-43f3-aea3-306e4aea1bd3"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","<ipython-input-40-52fddd500e17>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels = torch.tensor(labels)\n"]}],"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","for sent in sentences:\n","\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      \n","                        add_special_tokens = True, \n","                        max_length = 64,           \n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   \n","                        return_tensors = 'pt',    \n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Loading the trained model"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":3788,"status":"ok","timestamp":1681371298458,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"YypA-2_WgdRX"},"outputs":[],"source":["from transformers import BertForSequenceClassification\n","\n","model = BertForSequenceClassification.from_pretrained(output_dir)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Testing on custom data"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":734,"status":"ok","timestamp":1681377169531,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"4GkiyDH6gZ0n"},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","text = \"taste like good food\"\n","inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681377171683,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"jh2gK6gZgjkN"},"outputs":[],"source":["outputs = model(**inputs)\n","predictions = outputs.logits.argmax(dim=-1)\n"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1681377173908,"user":{"displayName":"Sashminda Withanage","userId":"13743672478236246053"},"user_tz":-330},"id":"7MRWvugugk4E","outputId":"9de9c3e3-c6ac-4b70-9b39-d8de050f0113"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1])\n"]}],"source":["print(predictions)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPE21q5zN606WupwHhWJrEY","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00163ee06c46415fb0e827656d3ccb94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0beaf9115c684616aa1e1480fd999ce1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20bdc3bd3354413ab254e9a9200241b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234beff55041477a9a2046c89f113b11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2baa9fb8bb564c11b8f8f5e873bba6df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c1b080a3a0643f2abb5dd92d17c829f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98bf441dffef40e79f60edd5ed092cf4","IPY_MODEL_4d801d28d0074b3da3a00add13c87dcb","IPY_MODEL_ba3ea9f9af844077bc283027afffe0b4"],"layout":"IPY_MODEL_8937f14c0ca4400092fbf1d58112d5ce"}},"380e65e0017948c09b25239ad9067d24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a363bb993ca346629f8c3e47e251df8a","placeholder":"​","style":"IPY_MODEL_234beff55041477a9a2046c89f113b11","value":" 28.0/28.0 [00:00&lt;00:00, 791B/s]"}},"4749f2be937840d1b13cd6c9a43b71d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88ce237423c94595b19b68c34106fa52","placeholder":"​","style":"IPY_MODEL_60df1875f5c34aa89ae74abb93b1f9a4","value":"Downloading (…)lve/main/config.json: 100%"}},"4bf63e5a7fdf42ed82a0f0b358d98d1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d801d28d0074b3da3a00add13c87dcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2baa9fb8bb564c11b8f8f5e873bba6df","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d779c69f8f7747338a053a5436704e1e","value":231508}},"547bf843181c485f956553bf6d49d3db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb6350825aa14b3bb2ae3eed42175de4","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_745baf921e454c569a8a686ba414c664","value":440473133}},"58cb8602816f448592eb31e323c088b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6347aab46197450cba320a4ad86a91a2","placeholder":"​","style":"IPY_MODEL_fc945f6679304803b67a8ddbd21a2b65","value":" 440M/440M [00:01&lt;00:00, 261MB/s]"}},"60df1875f5c34aa89ae74abb93b1f9a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"627b2ca479474d6a9a867145944b8b65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62d450eb94a847d4b6b85844f608f122":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6347aab46197450cba320a4ad86a91a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"745baf921e454c569a8a686ba414c664":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75f89bc8cb6940cc949c97db52449e26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a0cbb389744428b579a5f3a2232759":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62d450eb94a847d4b6b85844f608f122","placeholder":"​","style":"IPY_MODEL_0beaf9115c684616aa1e1480fd999ce1","value":" 570/570 [00:00&lt;00:00, 26.0kB/s]"}},"7b1743dab6fd4ae49a3e23c7110051ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"828de62350c741a880823c0ee0c5a151":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88ce237423c94595b19b68c34106fa52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8937f14c0ca4400092fbf1d58112d5ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ae9c45ab3144f508c23140c17a92e80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8251598d5de4a14a3e2891fd1591a49","IPY_MODEL_94808fcd55094fceb980d0cb2b9af30e","IPY_MODEL_380e65e0017948c09b25239ad9067d24"],"layout":"IPY_MODEL_af94071ef9c44c8490be16481298c1a0"}},"94808fcd55094fceb980d0cb2b9af30e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_627b2ca479474d6a9a867145944b8b65","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b54a35fd75284d0e8f1fded5ec0f53ed","value":28}},"98bf441dffef40e79f60edd5ed092cf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bf63e5a7fdf42ed82a0f0b358d98d1a","placeholder":"​","style":"IPY_MODEL_c43db8ce97c44b87a615ea96dec50cab","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"9f25d6361e3345f99a3ad013ca484288":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75f89bc8cb6940cc949c97db52449e26","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00163ee06c46415fb0e827656d3ccb94","value":570}},"a363bb993ca346629f8c3e47e251df8a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af027a9213124ca2bdc15a8571243424":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af94071ef9c44c8490be16481298c1a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b54a35fd75284d0e8f1fded5ec0f53ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b658939b3a164fa38186f05449166510":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f04d400437a4404bb8d6e078d7a72915","IPY_MODEL_547bf843181c485f956553bf6d49d3db","IPY_MODEL_58cb8602816f448592eb31e323c088b8"],"layout":"IPY_MODEL_af027a9213124ca2bdc15a8571243424"}},"b666eb5581e94905970d60d12c2745ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba3ea9f9af844077bc283027afffe0b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b666eb5581e94905970d60d12c2745ca","placeholder":"​","style":"IPY_MODEL_828de62350c741a880823c0ee0c5a151","value":" 232k/232k [00:00&lt;00:00, 4.88MB/s]"}},"c43db8ce97c44b87a615ea96dec50cab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d18abdd653bb4aa1be0b4db3310c4255":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4749f2be937840d1b13cd6c9a43b71d7","IPY_MODEL_9f25d6361e3345f99a3ad013ca484288","IPY_MODEL_76a0cbb389744428b579a5f3a2232759"],"layout":"IPY_MODEL_d8fb5d72c4bb4fb68e6793cc6c83e9ae"}},"d25f1c4a70d74e29a1f4936c454a2601":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d751f34b3bc34064af9b2b8fc533e6c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d779c69f8f7747338a053a5436704e1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8251598d5de4a14a3e2891fd1591a49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20bdc3bd3354413ab254e9a9200241b3","placeholder":"​","style":"IPY_MODEL_7b1743dab6fd4ae49a3e23c7110051ed","value":"Downloading (…)okenizer_config.json: 100%"}},"d8fb5d72c4bb4fb68e6793cc6c83e9ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb6350825aa14b3bb2ae3eed42175de4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f04d400437a4404bb8d6e078d7a72915":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d25f1c4a70d74e29a1f4936c454a2601","placeholder":"​","style":"IPY_MODEL_d751f34b3bc34064af9b2b8fc533e6c8","value":"Downloading pytorch_model.bin: 100%"}},"fc945f6679304803b67a8ddbd21a2b65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
